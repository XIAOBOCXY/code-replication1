import matplotlib.pyplot as plt
from sklearn.manifold import TSNE
import numpy as np
import torch
from torch.utils.data import DataLoader
import sys
import os

# å¤ç”¨ä½ å·²æœ‰çš„æ¨¡å—ï¼ˆç¡®ä¿è„šæœ¬è·¯å¾„èƒ½æ‰¾åˆ°dataset.pyå’Œtrain.pyï¼‰
# å¦‚æœè„šæœ¬å’Œdataset.pyä¸åœ¨åŒä¸€ç›®å½•ï¼Œéœ€è¦æ·»åŠ è·¯å¾„ï¼ˆç¤ºä¾‹ï¼šsys.path.append("/root/your_project_dir")ï¼‰
from dataset import build_dataset, build_transform
from train import read_yaml_to_dict  # å¤ç”¨é…ç½®è¯»å–å‡½æ•°
from model.mae_pipeline import Pipeline  # å¤ç”¨æ¨¡å‹ç»“æ„
from torch.nn.modules.distance import PairwiseDistance
from utils.metrics import triplet_prediction_accuracy  # å¤ç”¨ä¸‰å…ƒç»„å‡†ç¡®ç‡è®¡ç®—


def extract_triplet_features(model, dataloader, device):
    """æå–ä¸‰å…ƒç»„ï¼ˆanc/pos/negï¼‰çš„ç‰¹å¾å’Œæ ‡ç­¾"""
    model.eval()  # æ¨¡å‹è®¾ä¸ºè¯„ä¼°æ¨¡å¼
    all_features = []  # å­˜å‚¨æ‰€æœ‰ç‰¹å¾ï¼ˆanc+pos+negï¼‰
    all_labels = []    # æ ‡ç­¾ï¼š0=é”šç‚¹ï¼Œ1=æ­£æ ·æœ¬ï¼Œ2=è´Ÿæ ·æœ¬
    all_dists = []     # å­˜å‚¨è·ç¦»ï¼ˆanc-pos, anc-negï¼‰ç”¨äºå®šé‡æŒ‡æ ‡

    l2_dist = PairwiseDistance(2)  # è®¡ç®—L2è·ç¦»ï¼ˆå’Œtrain.pyä¸€è‡´ï¼‰

    with torch.no_grad():  # ç¦ç”¨æ¢¯åº¦ï¼ŒèŠ‚çœæ˜¾å­˜
        for batch in dataloader:
            # 1. åŠ è½½æ‰¹æ¬¡æ•°æ®ï¼ˆå¤ç”¨dataset.pyè¾“å‡ºçš„å­—å…¸æ ¼å¼ï¼‰
            anc_img = batch["anc"].to(device)
            pos_img = batch["pos"].to(device)
            neg_img = batch["neg"].to(device)
            triplet_type = batch["type"]  # ä¸‰å…ƒç»„ç±»å‹ï¼ˆç”¨äºåç»­åˆ†æï¼‰

            # 2. æå–ç‰¹å¾ï¼ˆå’Œtrain.pyé€»è¾‘ä¸€è‡´ï¼šæ‹¼æ¥å›¾åƒä¸€æ¬¡æ€§å‰å‘ä¼ æ’­ï¼‰
            batch_imgs = torch.cat((anc_img, pos_img, neg_img), dim=0)
            batch_features = model.forward(batch_imgs)

            # 3. æ‹†åˆ†ç‰¹å¾ï¼ˆanc/pos/negï¼‰
            batch_size = anc_img.shape[0]
            anc_fea, pos_fea, neg_fea = torch.split(batch_features, batch_size, dim=0)

            # 4. è®¡ç®—è·ç¦»ï¼ˆç”¨äºå®šé‡æŒ‡æ ‡ï¼‰
            dist_anc_pos = l2_dist(anc_fea, pos_fea).cpu().numpy()  # é”šç‚¹-æ­£ä¾‹è·ç¦»
            dist_anc_neg = l2_dist(anc_fea, neg_fea).cpu().numpy()  # é”šç‚¹-è´Ÿä¾‹è·ç¦»
            all_dists.append( (dist_anc_pos, dist_anc_neg, triplet_type) )

            # 5. æ”¶é›†ç‰¹å¾å’Œæ ‡ç­¾ï¼ˆç»™ä¸åŒæ ·æœ¬æ‰“æ ‡ç­¾ï¼‰
            all_features.extend(anc_fea.cpu().numpy())  # é”šç‚¹ï¼šæ ‡ç­¾0
            all_features.extend(pos_fea.cpu().numpy())  # æ­£æ ·æœ¬ï¼šæ ‡ç­¾1
            all_features.extend(neg_fea.cpu().numpy())  # è´Ÿæ ·æœ¬ï¼šæ ‡ç­¾2
            all_labels.extend([0]*batch_size + [1]*batch_size + [2]*batch_size)

    # è½¬æ¢ä¸ºnumpyæ•°ç»„ï¼ˆä¾¿äºåç»­å¤„ç†ï¼‰
    all_features = np.array(all_features)
    all_labels = np.array(all_labels)
    return all_features, all_labels, all_dists


def visualize_triplet(features_2d, labels, save_path):
    """ç»˜åˆ¶ä¸‰å…ƒç»„ç‰¹å¾çš„t-SNEå¯è§†åŒ–å›¾"""
    plt.figure(figsize=(12, 10))
    # ç»˜åˆ¶æ•£ç‚¹å›¾ï¼šä¸åŒé¢œè‰²ä»£è¡¨ä¸åŒæ ·æœ¬ç±»å‹
    scatter = plt.scatter(
        features_2d[:, 0], features_2d[:, 1],
        c=labels,          # æŒ‰æ ‡ç­¾ç€è‰²ï¼ˆ0=anc,1=pos,2=negï¼‰
        cmap="viridis",    # é¢œè‰²æ˜ å°„ï¼ˆ3ç§é¢œè‰²æ¸…æ™°åŒºåˆ†ï¼‰
        alpha=0.7,         # ç‚¹çš„é€æ˜åº¦ï¼ˆé¿å…é‡å é®æŒ¡ï¼‰
        s=60               # ç‚¹çš„å¤§å°
    )
    # æ·»åŠ å›¾ä¾‹å’Œæ ‡é¢˜
    plt.legend(
        handles=scatter.legend_elements()[0],
        labels=["é”šç‚¹(anc)", "æ­£æ ·æœ¬(pos)", "è´Ÿæ ·æœ¬(neg)"],
        fontsize=12
    )
    plt.title("ä¸‰å…ƒç»„ç‰¹å¾t-SNEå¯è§†åŒ–ï¼ˆé™ç»´è‡³2Dï¼‰", fontsize=14, pad=20)
    plt.xlabel("t-SNEç»´åº¦1", fontsize=10)
    plt.ylabel("t-SNEç»´åº¦2", fontsize=10)
    # ä¿å­˜å›¾ç‰‡ï¼ˆé«˜æ¸…ï¼‰
    plt.savefig(save_path, dpi=300, bbox_inches="tight")
    plt.close()
    print(f"âœ… å¯è§†åŒ–å›¾å·²ä¿å­˜è‡³ï¼š{save_path}")


def calculate_metrics(all_dists):
    """è®¡ç®—å®šé‡æŒ‡æ ‡ï¼Œåˆ¤æ–­æƒé‡å¥½åï¼ˆå’Œtrain.pyçš„è¯„ä¼°é€»è¾‘ä¸€è‡´ï¼‰"""
    all_dist_anc_pos = []
    all_dist_anc_neg = []
    all_types = []

    # æ•´ç†æ‰€æœ‰æ‰¹æ¬¡çš„è·ç¦»å’Œç±»å‹
    for dist_ap, dist_an, types in all_dists:
        all_dist_anc_pos.extend(dist_ap)
        all_dist_anc_neg.extend(dist_an)
        all_types.extend(types)

    # 1. ä¸‰å…ƒç»„å‡†ç¡®ç‡ï¼ˆæ ¸å¿ƒæŒ‡æ ‡ï¼‰ï¼šé”šç‚¹-æ­£ä¾‹è·ç¦» < é”šç‚¹-è´Ÿä¾‹è·ç¦» çš„æ¯”ä¾‹
    # ï¼ˆå‡†ç¡®ç‡è¶Šé«˜ï¼Œè¯´æ˜æ¨¡å‹è¶Šèƒ½åŒºåˆ†æ­£è´Ÿæ ·æœ¬ï¼‰
    overall_acc = triplet_prediction_accuracy(
        np.array(all_dist_anc_pos),
        np.array(all_dist_anc_neg)
    )

    # 2. å¹³å‡è·ç¦»åˆ†æï¼ˆè¾…åŠ©æŒ‡æ ‡ï¼‰
    avg_dist_ap = np.mean(all_dist_anc_pos)  # é”šç‚¹-æ­£ä¾‹å¹³å‡è·ç¦»ï¼ˆè¶Šå°è¶Šå¥½ï¼‰
    avg_dist_an = np.mean(all_dist_anc_neg)  # é”šç‚¹-è´Ÿä¾‹å¹³å‡è·ç¦»ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰
    dist_diff = avg_dist_an - avg_dist_ap    # è·ç¦»å·®ï¼ˆè¶Šå¤§è¶Šå¥½ï¼Œè¯´æ˜æ­£è´ŸåŒºåˆ†è¶Šæ˜æ˜¾ï¼‰

    # 3. æŒ‰ä¸‰å…ƒç»„ç±»å‹ç»Ÿè®¡å‡†ç¡®ç‡ï¼ˆå¯é€‰ï¼Œçœ‹ä¸åŒç±»å‹çš„è¡¨ç°ï¼‰
    type_acc_dict = {}
    unique_types = list(set(all_types))
    for t in unique_types:
        type_mask = [True if x == t else False for x in all_types]
        type_ap = np.array(all_dist_anc_pos)[type_mask]
        type_an = np.array(all_dist_anc_neg)[type_mask]
        type_acc = triplet_prediction_accuracy(type_ap, type_an)
        type_acc_dict[t] = type_acc

    # è¾“å‡ºæŒ‡æ ‡æ±‡æ€»
    print("\n" + "="*50)
    print("ğŸ“Š æƒé‡è´¨é‡å®šé‡æŒ‡æ ‡")
    print("="*50)
    print(f"æ•´ä½“ä¸‰å…ƒç»„å‡†ç¡®ç‡ï¼š{overall_acc:.4f}ï¼ˆè¶Šé«˜è¶Šå¥½ï¼Œå»ºè®®>0.8ï¼‰")
    print(f"é”šç‚¹-æ­£ä¾‹å¹³å‡è·ç¦»ï¼š{avg_dist_ap:.4f}ï¼ˆè¶Šå°è¶Šå¥½ï¼‰")
    print(f"é”šç‚¹-è´Ÿä¾‹å¹³å‡è·ç¦»ï¼š{avg_dist_an:.4f}ï¼ˆè¶Šå¤§è¶Šå¥½ï¼‰")
    print(f"è·ç¦»å·®ï¼ˆan - apï¼‰ï¼š{dist_diff:.4f}ï¼ˆè¶Šå¤§è¶Šå¥½ï¼Œå»ºè®®>0.1ï¼‰")
    for t, acc in type_acc_dict.items():
        print(f"ç±»å‹[{t}]å‡†ç¡®ç‡ï¼š{acc:.4f}")
    print("="*50 + "\n")

    return overall_acc, dist_diff


def main(config_path, weight_path, save_fig_path="triplet_visualization.png"):
    """ä¸»å‡½æ•°ï¼šåŠ è½½é…ç½®â†’åŠ è½½æ•°æ®â†’åŠ è½½æ¨¡å‹â†’æå–ç‰¹å¾â†’å¯è§†åŒ–â†’è¯„ä¼°"""
    # 1. åŠ è½½é…ç½®æ–‡ä»¶ï¼ˆå¤ç”¨train.pyçš„é€»è¾‘ï¼Œä¿è¯å‚æ•°ä¸€è‡´ï¼‰
    config = read_yaml_to_dict(config_path)
    print(f"ğŸ“Œ æˆåŠŸåŠ è½½é…ç½®æ–‡ä»¶ï¼š{config_path}")

    # 2. é…ç½®è®¾å¤‡ï¼ˆGPU/CPUï¼Œå’Œtrain.pyä¸€è‡´ï¼‰
    device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
    print(f"ğŸ”§ ä½¿ç”¨è®¾å¤‡ï¼š{device}")

    # 3. åŠ è½½éªŒè¯é›†ï¼ˆç”¨éªŒè¯æ¨¡å¼çš„transformï¼Œé¿å…æ•°æ®å¢å¼ºå½±å“ç‰¹å¾ï¼‰
    # æ³¨æ„ï¼šè¿™é‡Œç”¨valæ¨¡å¼çš„transformï¼ˆæ— å¢å¼ºï¼‰ï¼Œå’Œtrain.pyçš„valé€»è¾‘ä¸€è‡´
    val_transform = build_transform(is_train=False)  # å…³é”®ï¼šç¦ç”¨è®­ç»ƒæ—¶çš„å¢å¼º
    val_dataset = FecData(  # ç›´æ¥ç”¨dataset.pyçš„FecDataç±»
        csv_file=config["val_csv"],
        img_path=config["val_img_path"],
        transform=val_transform
    )
    # æ•°æ®åŠ è½½å™¨ï¼ˆbatch_sizeå¯è®¾å°äº›ï¼Œé¿å…æ˜¾å­˜ä¸è¶³ï¼‰
    val_loader = DataLoader(
        val_dataset,
        batch_size=config["batch_size"] // 2,  # æ˜¾å­˜ä¸å¤Ÿå¯å†å‡åŠ
        num_workers=config["num_workers"],
        shuffle=False  # éªŒè¯ä¸éœ€è¦æ‰“ä¹±
    )
    print(f"ğŸ“¥ åŠ è½½éªŒè¯é›†ï¼š{len(val_dataset)}ä¸ªæœ‰æ•ˆä¸‰å…ƒç»„æ ·æœ¬")

    # 4. åŠ è½½æ¨¡å‹å’Œæƒé‡ï¼ˆå’Œtrain.pyçš„æ¨¡å‹ç»“æ„å®Œå…¨ä¸€è‡´ï¼‰
    model = Pipeline(config).to(device)
    # åŠ è½½æƒé‡ï¼ˆå¤„ç†å¤šGPUè®­ç»ƒçš„æƒ…å†µï¼‰
    try:
        state_dict = torch.load(weight_path, map_location=device)
        # å¦‚æœè®­ç»ƒæ—¶ç”¨äº†DataParallelï¼Œæƒé‡é”®ä¼šæœ‰"module."å‰ç¼€ï¼Œéœ€è¦å¤„ç†
        if next(iter(state_dict.keys())).startswith("module."):
            state_dict = {k.replace("module.", ""): v for k, v in state_dict.items()}
        model.load_state_dict(state_dict)
        print(f"âœ… æˆåŠŸåŠ è½½æƒé‡æ–‡ä»¶ï¼š{weight_path}")
    except Exception as e:
        print(f"âŒ æƒé‡åŠ è½½å¤±è´¥ï¼š{e}")
        sys.exit(1)

    # 5. æå–ä¸‰å…ƒç»„ç‰¹å¾
    print("\nğŸ” å¼€å§‹æå–ç‰¹å¾...")
    all_features, all_labels, all_dists = extract_triplet_features(model, val_loader, device)
    print(f"âœ… ç‰¹å¾æå–å®Œæˆï¼šå…±{len(all_features)}ä¸ªæ ·æœ¬ï¼ˆæ¯ä¸ªä¸‰å…ƒç»„3ä¸ªæ ·æœ¬ï¼‰")

    # 6. t-SNEé™ç»´ï¼ˆé«˜ç»´ç‰¹å¾â†’2Dï¼Œä¾¿äºå¯è§†åŒ–ï¼‰
    print("\nğŸ”„ æ­£åœ¨ç”¨t-SNEé™ç»´...")
    tsne = TSNE(
        n_components=2,    # é™ç»´åˆ°2ç»´
        random_state=42,   # å›ºå®šéšæœºç§å­ï¼Œç»“æœå¯å¤ç°
        perplexity=30,     # æ¨èå€¼ï¼ˆæ ·æœ¬æ•°å¤šå¯è®¾å¤§äº›ï¼Œå¦‚50ï¼‰
        n_iter=1000        # è¿­ä»£æ¬¡æ•°ï¼Œä¿è¯é™ç»´æ•ˆæœ
    )
    features_2d = tsne.fit_transform(all_features)
    print("âœ… t-SNEé™ç»´å®Œæˆ")

    # 7. å¯è§†åŒ–å¹¶ä¿å­˜
    visualize_triplet(features_2d, all_labels, save_fig_path)

    # 8. è®¡ç®—å®šé‡æŒ‡æ ‡ï¼Œåˆ¤æ–­æƒé‡å¥½å
    calculate_metrics(all_dists)


if __name__ == "__main__":
    # å‘½ä»¤è¡Œå‚æ•°ï¼šæ–¹ä¾¿åˆ‡æ¢ä¸åŒæƒé‡æ–‡ä»¶
    import argparse
    parser = argparse.ArgumentParser(description="ä¸‰å…ƒç»„ç‰¹å¾å¯è§†åŒ–ä¸æƒé‡è¯„ä¼°")
    parser.add_argument(
        "--config", 
        required=True,
        help="é…ç½®æ–‡ä»¶è·¯å¾„ï¼ˆå’Œtrain.pyç”¨åŒä¸€ä¸ªï¼Œå¦‚configs/mae_train_expemb.yamlï¼‰"
    )
    parser.add_argument(
        "--weight", 
        required=True,
        help="è®­ç»ƒå¥½çš„æƒé‡æ–‡ä»¶è·¯å¾„ï¼ˆå¦‚checkpoint/epoch_10_acc_0.85.pthï¼‰"
    )
    parser.add_argument(
        "--save_fig", 
        default="triplet_feature_vis.png",
        help="å¯è§†åŒ–å›¾ä¿å­˜è·¯å¾„ï¼ˆé»˜è®¤ï¼štriplet_feature_vis.pngï¼‰"
    )
    args = parser.parse_args()

    # å¯åŠ¨æµç¨‹
    main(
        config_path=args.config,
        weight_path=args.weight,
        save_fig_path=args.save_fig
    )